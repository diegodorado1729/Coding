{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegodorado1729/Coding/blob/main/Python/CD-2024/Tarea4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-J_MSrNUKhL"
      },
      "source": [
        "# Tarea Nº4: Mitigación de ruido con PCA\n",
        "---------------------------------------------\n",
        "Santiago Ferreyra (LF), Diego Dorado (LF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jX-gQwWXT48l"
      },
      "outputs": [
        {
          "ename": "ArgumentError",
          "evalue": "ArgumentError: Package numpy not found in current path.\n- Run `import Pkg; Pkg.add(\"numpy\")` to install the numpy package.",
          "output_type": "error",
          "traceback": [
            "ArgumentError: Package numpy not found in current path.\n",
            "- Run `import Pkg; Pkg.add(\"numpy\")` to install the numpy package.\n",
            "\n",
            "Stacktrace:\n",
            "  [1] macro expansion\n",
            "    @ .\\loading.jl:1772 [inlined]\n",
            "  [2] macro expansion\n",
            "    @ .\\lock.jl:267 [inlined]\n",
            "  [3] __require(into::Module, mod::Symbol)\n",
            "    @ Base .\\loading.jl:1753\n",
            "  [4] #invoke_in_world#3\n",
            "    @ .\\essentials.jl:926 [inlined]\n",
            "  [5] invoke_in_world\n",
            "    @ .\\essentials.jl:923 [inlined]\n",
            "  [6] require(into::Module, mod::Symbol)\n",
            "    @ Base .\\loading.jl:1746\n",
            "  [7] eval\n",
            "    @ .\\boot.jl:385 [inlined]\n",
            "  [8] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
            "    @ Base .\\loading.jl:2076\n",
            "  [9] #invokelatest#2\n",
            "    @ .\\essentials.jl:892 [inlined]\n",
            " [10] invokelatest\n",
            "    @ .\\essentials.jl:889 [inlined]\n",
            " [11] (::VSCodeServer.var\"#219#220\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
            "    @ VSCodeServer c:\\Users\\Diego Dorado\\.vscode\\extensions\\julialang.language-julia-1.79.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:19\n",
            " [12] withpath(f::VSCodeServer.var\"#219#220\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
            "    @ VSCodeServer c:\\Users\\Diego Dorado\\.vscode\\extensions\\julialang.language-julia-1.79.2\\scripts\\packages\\VSCodeServer\\src\\repl.jl:276\n",
            " [13] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
            "    @ VSCodeServer c:\\Users\\Diego Dorado\\.vscode\\extensions\\julialang.language-julia-1.79.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:13\n",
            " [14] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
            "    @ VSCodeServer.JSONRPC c:\\Users\\Diego Dorado\\.vscode\\extensions\\julialang.language-julia-1.79.2\\scripts\\packages\\JSONRPC\\src\\typed.jl:67\n",
            " [15] serve_notebook(pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; crashreporting_pipename::String)\n",
            "    @ VSCodeServer c:\\Users\\Diego Dorado\\.vscode\\extensions\\julialang.language-julia-1.79.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:139\n",
            " [16] top-level scope\n",
            "    @ c:\\Users\\Diego Dorado\\.vscode\\extensions\\julialang.language-julia-1.79.2\\scripts\\notebook\\notebook.jl:35"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import statistics\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o6PK7UaUW6X"
      },
      "source": [
        "## Parte 1: Digits dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RESCp0ZtUfcA"
      },
      "source": [
        "### a) Considerar el dataset Digits provisto por scikit-learn. Determinar el número de features, samples y classes y el tamaño en píxeles de las imágenes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4Hefa8IVYX0",
        "outputId": "dbbd3008-9fb0-484c-8d4a-b8d2a7a33bb1"
      },
      "outputs": [
        {
          "ename": "UndefVarError",
          "evalue": "UndefVarError: `from` not defined",
          "output_type": "error",
          "traceback": [
            "UndefVarError: `from` not defined\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()       # type(digits) >>  <class 'sklearn.utils._bunch.Bunch'>\n",
        "target_names = digits.target_names\n",
        "\n",
        "n_features = len(digits.feature_names)\n",
        "n_samples = len(digits.images)\n",
        "n_clases = len(digits.target_names)\n",
        "tam_imagenes = np.shape(digits.images)[-2:]\n",
        "\n",
        "print()\n",
        "print(\"features\",n_features)\n",
        "print(\"samples\",n_samples)\n",
        "print(\"classes\", n_clases)\n",
        "print(\"tam imagenes\", tam_imagenes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIN6HvLrUl2I"
      },
      "source": [
        "### b) Separar un conjunto de entrenamiento reservando un 25 % de los datos para test. Estratificar los conjuntos usando la clase y usar la semilla 42. A continuación normalizar los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41icRDOxViV0",
        "outputId": "63d5a059-5d37-4675-9b25-5103ca945959"
      },
      "outputs": [
        {
          "ename": "ErrorException",
          "evalue": "type #digits has no field data",
          "output_type": "error",
          "traceback": [
            "type #digits has no field data\n",
            "\n",
            "Stacktrace:\n",
            " [1] getproperty(x::Function, f::Symbol)\n",
            "   @ Base .\\Base.jl:37\n",
            " [2] top-level scope\n",
            "   @ d:\\DIEGO\\COMPUTADORAS\\Coding\\Python\\CD-2024\\Tarea4.ipynb:2"
          ]
        }
      ],
      "source": [
        "# Separar las características (X) y las etiquetas (y)\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba (75% entrenamiento, 25% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "# Verificar las formas de los conjuntos\n",
        "print(\"Forma de X_train_normalized:\", X_train_normalized.shape)\n",
        "print(\"Forma de X_test_normalized:\", X_test_normalized.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RX-hWVZAVN9e"
      },
      "outputs": [
        {
          "ename": "UndefVarError",
          "evalue": "UndefVarError: `X_train_normalized` not defined",
          "output_type": "error",
          "traceback": [
            "UndefVarError: `X_train_normalized` not defined\n",
            "\n",
            "Stacktrace:\n",
            " [1] top-level scope\n",
            "   @ d:\\DIEGO\\COMPUTADORAS\\Coding\\Python\\CD-2024\\Tarea4.ipynb:1"
          ]
        }
      ],
      "source": [
        "X_train = X_train_normalized\n",
        "X_test = X_test_normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_RHzFtQUnnT"
      },
      "source": [
        "### c) Graficar las primeras 10 imagenes, respetando el factor de forma original. ¿Cuál es?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "PLsLStd4Z35L",
        "outputId": "29a87167-5df5-4f7f-ad31-a6f3ac0cc868"
      },
      "outputs": [
        {
          "ename": "UndefVarError",
          "evalue": "UndefVarError: `plt` not defined",
          "output_type": "error",
          "traceback": [
            "UndefVarError: `plt` not defined\n",
            "\n",
            "Stacktrace:\n",
            " [1] top-level scope\n",
            "   @ d:\\DIEGO\\COMPUTADORAS\\Coding\\Python\\CD-2024\\Tarea4.ipynb:2"
          ]
        }
      ],
      "source": [
        "# Graficar las primeras 10 imágenes\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(10, 4))\n",
        "\n",
        "for ax, image, label in zip(axes.flat, X[:10], y[:10]):\n",
        "    ax.imshow(image.reshape(8, 8), cmap='gray')\n",
        "    ax.set_title(f'Label: {label}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVDRHo0fgjWY"
      },
      "source": [
        "El tamaño de la figura se ajusta para respetar el factor de forma original de las imágenes (8x8 píxeles)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43aB95-HaDnw"
      },
      "source": [
        "## Parte 2: Hyperparameter Tunning of k-nearest Neighbors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTLleSmpbbM-"
      },
      "source": [
        "### d) Implementar una búsqueda del valor óptimo de vecinos cercanos para KNeighborsClassifier, usando el modelo GridSearchCV, ambos de scikit-learn. Usar los valores default de los parámetros de KNeighborsClassifier, ¿qué métrica de distancia se usa? Realizar la búsqueda con k ∈ {2, 3, 4, 5, 6, 7, 8, 9, 10}, usando 10-fold cross-validation. ¿De qué tamaño resultan los conjuntos de validación?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iro-1QCpb6G3",
        "outputId": "e69c6769-d1dd-47da-a600-b31d30823013"
      },
      "outputs": [
        {
          "ename": "UndefVarError",
          "evalue": "UndefVarError: `from` not defined",
          "output_type": "error",
          "traceback": [
            "UndefVarError: `from` not defined\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Definir el modelo KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Definir los parámetros a buscar\n",
        "param_grid = {'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
        "\n",
        "# Definir el GridSearchCV con 10-fold cross-validation\n",
        "grid_search = GridSearchCV(knn_model, param_grid, cv=10)\n",
        "\n",
        "# Entrenar el modelo usando GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(\"Mejor valor de k encontrado:\", grid_search.best_params_['n_neighbors'])\n",
        "print(\"Exactitud del mejor modelo en conjunto de prueba:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Según la documentación del [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), el valor default para la métrica es **'minkowski'**\n",
        "\n",
        "Por otro lado, para realizar la cross validation usamos 10 folds. Cuando el modelo es entrenado, sólo se usan $k-1$ de los folds como data de entrenamiento. Por lo tanto tendremos **9 conjuntos de validación**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVnIA72ybfYu"
      },
      "source": [
        "\n",
        "### e) Reportar el mejor valor de k hallado y el correspondiente mean test score. Graficar accuracy en función de k ∈ {2, 3, 4, 5, 6, 7, 8, 9, 10}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "8IDB_LntkLFi",
        "outputId": "be8fe7d8-355d-4a70-f3fb-3a5e5d6027b2"
      },
      "outputs": [],
      "source": [
        "# Obtener los resultados de GridSearchCV\n",
        "results = grid_search.cv_results_\n",
        "k_values = param_grid['n_neighbors']\n",
        "mean_test_scores = results['mean_test_score']\n",
        "\n",
        "# Encontrar el índice del mejor valor de k\n",
        "best_k_idx = np.argmax(mean_test_scores)\n",
        "best_k = k_values[best_k_idx]\n",
        "best_score = mean_test_scores[best_k_idx]\n",
        "\n",
        "# Reportar el mejor valor de k y el mean test score correspondiente\n",
        "print(\"Mejor valor de k encontrado:\", best_k)\n",
        "print(\"Mean test score correspondiente:\", best_score)\n",
        "\n",
        "# Graficar accuracy en función de k\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_values, mean_test_scores, marker='o')\n",
        "plt.title(\"Exactitud vs. Valor de k\")\n",
        "plt.xlabel(\"Valor de k\")\n",
        "plt.ylabel(\"Exactitud media en validación cruzada\")\n",
        "plt.xticks(k_values)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmZ3Ro9xbhsw"
      },
      "source": [
        "\n",
        "### f) Evaluar KNeighborsClassifier con valor de k óptimo sobre el set de test. Reportar la salida de classification report y mostrar la matriz de confusión. ¿Qué dígitos se confunden con cuales otros? ¿Condice la accuracy sobre el set de test con la mejor encontrada en la búsqueda en grilla? ¿Puede decirse que el modelo sufre de overfitting? Explicar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "wvFrE3Tmv7CF",
        "outputId": "35f36e6f-f07c-4e2d-af64-2ec52cf18441"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Crear un nuevo modelo KNeighborsClassifier con el mejor valor de k encontrado\n",
        "best_knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento completos (X_train, y_train)\n",
        "best_knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "y_pred = best_knn_model.predict(X_test)\n",
        "\n",
        "# Mostrar el classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "print(\"Matriz Confusión:\\n\")\n",
        "ConfusionMatrixDisplay.from_predictions(y_test,y_pred,display_labels=target_names)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xauxexWz3Mm"
      },
      "source": [
        "## Parte 3: PCA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mNgUIEc0wwh"
      },
      "source": [
        "\n",
        "### g) Calcular PCA con 30 componentes sobre el conjunto de entrenamiento. Graficar la varianza explicada acumulada en función del número de componentes. Verificar en el gráfico que el 70 % de la varianza acumulada se explica con aproximadamente sólo 14 componentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "hn-b9bzV1aJ3",
        "outputId": "6f15b96d-3f53-4006-d273-fb7ae3b58abc"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular PCA con 30 componentes sobre el conjunto de entrenamiento\n",
        "pca = PCA(n_components=30)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "\n",
        "# Obtener la varianza explicada acumulada\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "# Graficar la varianza explicada acumulada en función del número de componentes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(0, 30), cumulative_variance_ratio, marker='o')\n",
        "plt.title(\"Varianza Explicada Acumulada\")\n",
        "plt.xlabel(\"Número de Componentes Principales\")\n",
        "plt.ylabel(\"Varianza Explicada Acumulada\")\n",
        "plt.axhline(y=0.7, color='r', linestyle='--', label='70% de varianza explicada')\n",
        "plt.axvline(x=np.where(cumulative_variance_ratio >= 0.7)[0][0], color='g', linestyle='--', label='Aprox. 14 componentes')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40L-0oiS00c8"
      },
      "source": [
        "\n",
        "### h) Reconstruir los dígitos con 14 componentes de PCA y graficar en dos filas los 10 primeros dígitos originales (normalizados) de entrenamiento y los correspondientes reconstruidos para comparar las imágenes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "_sblQ1-H2Zge",
        "outputId": "b1f4bf28-8860-4bd8-bac7-eeec8329947b"
      },
      "outputs": [],
      "source": [
        "# Re-entrenar PCA con 14 componentes\n",
        "pca_14 = PCA(n_components=14)\n",
        "X_train_pca_14 = pca_14.fit_transform(X_train)\n",
        "\n",
        "# Reconstruir los dígitos con 14 componentes\n",
        "X_train_reconstructed = pca_14.inverse_transform(X_train_pca_14)\n",
        "\n",
        "# Graficar los dígitos originales y los reconstruidos\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, figsize=(12, 4))\n",
        "\n",
        "# Graficar los 10 primeros dígitos originales\n",
        "for i, ax in enumerate(axes[0]):\n",
        "    ax.imshow(X_train_normalized[i].reshape(8, 8), cmap='gray')\n",
        "    ax.axis('off')\n",
        "\n",
        "# Graficar los 10 primeros dígitos reconstruidos\n",
        "for i, ax in enumerate(axes[1]):\n",
        "    ax.imshow(X_train_reconstructed[i].reshape(8, 8), cmap='gray')\n",
        "    ax.axis('off')\n",
        "\n",
        "axes[0, 0].set_title(\"Original\")\n",
        "axes[1, 0].set_title(\"Reconstruido\")\n",
        "\n",
        "plt.suptitle(\"Comparación de Dígitos Originales y Reconstruidos\")\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1B9pG7f02QY"
      },
      "source": [
        "\n",
        "### i) Entrenar y evaluar KNeighborsClassifier con valor de k óptimo, usando los sets transformados con PCA de 14 componentes. Evaluar el modelo usando las métricas del ítem (f) y comparar los resultados de ambos ítems. Expresar una conclusión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIwnz9Ei39k2",
        "outputId": "b2135073-1d03-4661-a902-45111dfb3414"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Entrenar el modelo KNeighborsClassifier con el valor de k óptimo\n",
        "best_knn_model_pca = KNeighborsClassifier(n_neighbors=best_k)\n",
        "best_knn_model_pca.fit(X_train_pca_14, y_train)\n",
        "\n",
        "# Transformar el conjunto de prueba utilizando PCA de 14 componentes\n",
        "X_test_pca_14 = pca_14.transform(X_test)\n",
        "\n",
        "# Predecir las etiquetas del conjunto de prueba\n",
        "y_pred_pca_14 = best_knn_model_pca.predict(X_test_pca_14)\n",
        "\n",
        "# Calcular métricas de evaluación\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_pca_14))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Comparación de las métricas obtenidas "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiboiUUh5eq9"
      },
      "source": [
        "Este código entrena el modelo KNeighborsClassifier con el valor de k óptimo utilizando los datos transformados con PCA de 14 componentes (X_train_pca_14). Luego, se transforma el conjunto de prueba con PCA de 14 componentes (X_test_pca_14) y se evalúa el modelo utilizando las métricas de precisión, recall, F1-score y exactitud (accuracy).\n",
        "\n",
        "Comparando estos resultados con las métricas obtenidas sin PCA, puedes hacer una conclusión sobre cómo la reducción de dimensionalidad afecta el rendimiento del modelo. Es probable que las métricas con PCA sean un poco más bajas debido a la pérdida de información al reducir la dimensionalidad, pero esto puede ser aceptable si se logra una reducción significativa en la complejidad del modelo y los tiempos de entrenamiento/evaluación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijPWLGzY5kBh"
      },
      "source": [
        "## Parte 4: Datos con ruido\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2dyrV9u6pUJ"
      },
      "source": [
        "### j) Ofuscar las imágenes agregando ruido usando: np.random.normal(digits.data,2). Explicar en qué consiste esta transformación de los píxeles. ¿Qué tipo de ruido se agregó a las imágenes?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra-QVbz07vnZ"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "Xnoisy = np.random.normal(X, 2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    Xnoisy, y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGvTWMju77XN"
      },
      "source": [
        "Aquí lo que se hace es almacenar en X_noisy una matriz de números aleatorios generados a partir de una distribución normal centrada en los valores de X y una dispersión dada por una desviación estándar de 4.\n",
        "\n",
        "Luego, cada uno de estos ruidos se le agrega a cada una de las imágenes.\n",
        "\n",
        "Vemos a continuación una comparación entre las primeras 20 imágenes, el ruido que se le agrega a cada una y la imagen con ruido. Luego, vemos las mismas imagenes con diferentes valores de la dispersión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjna46jm7ZAG"
      },
      "source": [
        "\n",
        "La transformación de los píxeles al agregar ruido usando np.random.normal(digits.data, 2) consiste en generar un ruido aleatorio gaussiano y agregarlo a cada píxel de las imágenes. En este caso, se utiliza la función np.random.normal para generar muestras aleatorias de una distribución normal (gaussiana) con una media de cero y una desviación estándar de 2. Estas muestras aleatorias se suman a los valores de los píxeles de las imágenes originales.\n",
        "\n",
        "En términos simples, este proceso introduce variaciones aleatorias en los valores de los píxeles de las imágenes, lo que afecta su apariencia visual. La cantidad de ruido agregado está determinada por la desviación estándar especificada (en este caso, 2).\n",
        "\n",
        "El tipo de ruido que se agrega a las imágenes es ruido gaussiano, también conocido como ruido aditivo gaussiano (Gaussian Additive Noise). Este tipo de ruido es aleatorio y sigue una distribución normal, lo que significa que los valores generados son más probables de estar cerca de cero y menos probables de estar lejos de cero, según la desviación estándar especificada. Este ruido puede tener un impacto diferente en la percepción visual dependiendo de la desviación estándar utilizada, ya que una desviación estándar mayor genera más variaciones aleatorias en los valores de los píxeles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtwjFu326tSO"
      },
      "source": [
        "\n",
        "### k) Reproducir los tres ítems de la parte 3. Verificar en el gráfico ídem a (g) que 26 componentes explican el 75 % de la varianza acumulada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgsrjLxPBpT-"
      },
      "outputs": [],
      "source": [
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train_r = scaler.fit_transform(X_train)\n",
        "X_test_r = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "9cvpiE3C9JUv",
        "outputId": "7fbc84c5-0108-4368-a380-51f45bb5980e"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular PCA con 30 componentes sobre el conjunto de entrenamiento\n",
        "pca = PCA(n_components=30)\n",
        "X_train_pca = pca.fit_transform(X_train_r)\n",
        "\n",
        "# Obtener la varianza explicada acumulada\n",
        "explained_variance_ratio_r = pca.explained_variance_ratio_\n",
        "cumulative_variance_ratio_r = np.cumsum(explained_variance_ratio_r)\n",
        "\n",
        "# Graficar la varianza explicada acumulada en función del número de componentes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(0, 30), cumulative_variance_ratio_r, marker='o')\n",
        "plt.title(\"Varianza Explicada Acumulada\")\n",
        "plt.xlabel(\"Número de Componentes Principales\")\n",
        "plt.ylabel(\"Varianza Explicada Acumulada\")\n",
        "plt.axhline(y=0.75, color='r', linestyle='--', label='70% de varianza explicada')\n",
        "plt.axvline(x=np.where(cumulative_variance_ratio_r >= 0.74)[0][0], color='g', linestyle='--', label='Aprox. 14 componentes')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "9Fgx952M8aby",
        "outputId": "fdb1a807-7ea7-4254-bd0c-9ed4bb6dec10"
      },
      "outputs": [],
      "source": [
        "# Re-entrenar PCA con 26 componentes\n",
        "pca_26 = PCA(n_components=26)\n",
        "X_train_pca_26 = pca_26.fit_transform(X_train_r)\n",
        "\n",
        "# Reconstruir los dígitos con 14 componentes\n",
        "X_train_reconstructed = pca_26.inverse_transform(X_train_pca_26)\n",
        "\n",
        "# Graficar los dígitos originales y los reconstruidos\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, figsize=(12, 4))\n",
        "\n",
        "# Graficar los 10 primeros dígitos originales\n",
        "for i, ax in enumerate(axes[0]):\n",
        "    ax.imshow(X_train[i].reshape(8, 8), cmap='gray')\n",
        "    ax.axis('off')\n",
        "\n",
        "# Graficar los 10 primeros dígitos reconstruidos\n",
        "for i, ax in enumerate(axes[1]):\n",
        "    ax.imshow(X_train_reconstructed[i].reshape(8, 8), cmap='gray')\n",
        "    ax.axis('off')\n",
        "\n",
        "axes[0, 0].set_title(\"Original\")\n",
        "axes[1, 0].set_title(\"Reconstruido\")\n",
        "\n",
        "plt.suptitle(\"Comparación de Dígitos Originales y Reconstruidos\")\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yISf3Vnj8eov",
        "outputId": "7afc8d4b-a64b-442e-95ce-dcfcbd29922e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Entrenar el modelo KNeighborsClassifier con el valor de k óptimo\n",
        "best_knn_model_pca = KNeighborsClassifier(n_neighbors=best_k)\n",
        "best_knn_model_pca.fit(X_train_pca_26, y_train)\n",
        "\n",
        "# Transformar el conjunto de prueba utilizando PCA de 26 componentes\n",
        "X_test_pca_26 = pca_26.transform(X_test)\n",
        "\n",
        "# Predecir las etiquetas del conjunto de prueba\n",
        "y_pred_pca_26 = best_knn_model_pca.predict(X_test_pca_26)\n",
        "\n",
        "# Calcular métricas de evaluación\n",
        "print(classification_report(y_test, y_pred_pca_26))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDsRloHG6v5A"
      },
      "source": [
        "\n",
        "### l) Discutir cuál es el efecto y la utilidad de usar PCA sobre datos afectados por ruido."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "python",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
